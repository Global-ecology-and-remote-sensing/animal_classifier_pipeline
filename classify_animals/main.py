import json
import pickle
import os
import math
import logging
import shutil
import pandas as pd
from tensorflow import keras as kr
from tqdm import tqdm
from classify_animals.scripts import config, crop_images, identify_species
from os import path

def main(
    bb_results_path, 
    image_dir, 
    model_path, 
    working_data_dir = None, 
    keep_crops: bool = True ,
    md_thr = 0.2, 
    ent_thr = None, 
    batch_size: int = 32 , 
    classifier_batch_size: int = None , 
    use_checkpoints: bool = True ,
    show_progress_bar: bool = True 
):
    """
    Crops animal detections generated by Megadetector and sorts crops
    by species of animal
    
    bb_results_path (String or Python PATH object): Path to 
        Megadetector's JSON string output for bounding boxes. 
        Can either by a Pyrhon PATH object, absolute or 
        relative path
    
    image_dir (String or Python PATH object): Path to directory
        that contains raw camera trap images. This path must
        be the same as the one that was used to generate the 
        megadetector bounding boxes. That is to say, the relative
        file paths in the JSON string outputted by megadetector must
        be relative to the path given by image_dir.
    
    model_path (String or Python PATH object) : Path to pre-trained
        weights for the classifier
    
    working_data_dir (String or Python PATH object) : Path
        to directory that will contain the temporary files
        the program needs to use to run and the output of
        the program. if set to None, it will default to saving
        the output to a folder that lies in the working directory
        
    keep_crops (Bool) : If True, Megadetector's animal detections
        will be cropped and saved to the working data_dir. Furthermore,
        the crops will be sorted by the species that the neural network
        detected them to be
        
    md_thr (float) : Threshold value for the confidence ratings of
        Megadetector's detections. Only bounding boxes with a confidence
        rating above the threshold will be cropped and analysed. A higher
        threshold means that detections are more likely to be of an animal
        but it also makes it more likely that fewer animals will be detected
        
    ent_thr (float) : Threshold value for confidence rating in neural network's
        classifications. Confidence rating is Shannon Entropy of the network's
        output and therefore only classifications that have an entropy below the 
        threshold will be assigned to their crops. A lower threshold will increase
        the precision of the classifier however it also means that more animal
        detections will be labelled as having an unknown species. If an entropy
        threshold is used then a cut-off of 1.0 might be a good value to start at
        although this hasn't been properly tested.
        
    batch_size (int) : Number of images to process at a time. Lowering this number
        should reduce the program's requirement for memory and storage space. Raising
        this should will likely reduce the overall time it takes for the neural network
        to process the images
    
    classifier_batch_size (int) : Batch size for images as they're processed by the
        neural network classifier. By default, its half of the batch size of the cropping
        algorithm rounded up to the nearest integer. Classifier_batch_size should be at
        most batch_size
    
    use_checkpoints (Bool): If True, the program will start from check points found
        in working_data_dir, which is useful if program stops during processing. If
        False, the program will start the whole process from scratch and overwrite
        checkpoints
        
    show_progress_bar (Bool): If True, a progress bar will be displayed
    """
    
    # Set nn batch size to default value if none was passed
    if classifier_batch_size == None:
        classifier_batch_size = math.ceil(batch_size / 2)
    
    # If no working directory was passed to the program
    if working_data_dir == None:
        
        # Set default working directory
        working_data_dir = path.join(os.getcwd(), config.WORK_DIR_DEFAULT_NAME) 
    
    # Build dictionary of file paths used by the program
    path_dict = config.build_working_file_dict(working_data_dir)
    
    # If checkpoints exist and should be used
    if use_checkpoints and config.all_checkpoints_exist(path_dict):
        
        # Load Checkpoints
        df_bb = pd.read_csv(path_dict['bb_csv_path'])
        with open(path_dict['crop_checkpoint_path'], 'rb') as file:
            crops = pickle.load(file)
        with open(path_dict['batch_number_path'], 'r') as file:
            start_row_number = json.load(file)
        
    else:
        
        # Otherwise, create data structures for batch-classifying
        # data from scratch
        df_bb, crops, start_row_number = config.initialise_checkpoints(bb_results_path, md_thr)
        
        # Save CSV on bounding box information
        config.save_csv(df_bb, path_dict['bb_csv_path'], save_index = False)
        
        # Save checkpoint
        config.save_checkpoint(crops, start_row_number, path_dict)
    
    
    # Load trained classifier
    model = kr.models.load_model(model_path)
    
    # Process images in batches
    for i in tqdm(range(start_row_number, df_bb.shape[0], batch_size), disable = not show_progress_bar):
    
        # Get bounding boxes for batch
        df_bb_batch = df_bb.iloc[i : i + batch_size].copy() 
        
        # Get folder that crops from batch will be put into
        batch_subfolder = 'crops_' + str(i) 
        
        # Crop images
        df_crop_batch = crop_images.main(
            df_bb = df_bb_batch, 
            source_dir = image_dir, 
            target_dir = path_dict['unsorted_cropped_images_dir'],
            subfolder_name = batch_subfolder
        )
        
        # Identify Species
        df_crop_batch = identify_species.main(
            df_crop = df_crop_batch, 
            root_dir = path_dict['unsorted_cropped_images_dir'],
            img_dir = path.join(path_dict['unsorted_cropped_images_dir'], batch_subfolder), 
            model = model, 
            batch_size = classifier_batch_size, 
            ent_thr = ent_thr
        )
        
        # If crops should not be saved
        if not keep_crops: 
            
            # Delete cropped image files for this batch
            df_crop_batch[config.CROP_COL_NAME].apply(
                lambda x : os.remove(path.join(path_dict['unsorted_cropped_images_dir'], x))
            )
            
            # Delete batch subfolder
            os.rmdir(path.join(path_dict['unsorted_cropped_images_dir'], batch_subfolder))
            
            # Delete crop file paths from batch
            df_crop_batch.drop(columns = config.CROP_COL_NAME, inplace = True)
        
        # Add crops to list of crops
        crops.append(df_crop_batch)
        
        # Save checkpoint
        config.save_checkpoint(crops, i + batch_size, path_dict)
        
        # Log progress
        logging.info(f'Processed {i + batch_size} crops')
    
    
    # Clear classifier from memory
    kr.backend.clear_session() 
    
    # Compile animal labels
    df_crop = pd.concat(crops, ignore_index = True)
    
    # If crops should be saved
    if keep_crops: 
        
        # Sort cropped files by species
        df_crop = df_crop.groupby(
            config.SPECIES_COL_NAME, 
            group_keys = False
        ).apply(
            lambda x : config.sort_by_species(
                df = x, 
                old_dir = path_dict['unsorted_cropped_images_dir'], 
                new_dir = path_dict['sorted_cropped_images_dir'], 
                species = x.name, 
                path_col_name = config.CROP_COL_NAME
            )
        )
        
        # Delete unsorted_cropped_images folder
        config.delete_folder_if_empty(path_dict['unsorted_cropped_images_dir'])
    
    # Save final animal labels
    config.save_csv(df_crop, path_dict['output_path'], save_index = False)
    
    # Delete checkpoints
    shutil.rmtree(path_dict['checkpoint_dir'])